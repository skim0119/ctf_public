{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CtF-Game Policy Tournament\n",
    "\n",
    "- Simple script to test the performance of individual policy.\n",
    "- Graph the success rate, reward, and episode length.\n",
    "- Script __does not__ include the rendering\n",
    "\n",
    "## TODO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import gym\n",
    "import gym_cap\n",
    "import numpy as np\n",
    "\n",
    "# the modules that you can use to generate the policy.\n",
    "import policy.patrol \n",
    "import policy.random\n",
    "import policy.simple # custon written policy\n",
    "import policy.policy_RL\n",
    "import policy.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B4R4_Rzero_SyncA2C',\n",
       " 'B4R4_Rzero_VANILLA',\n",
       " 'B2R2_Rzero_AC_ImportSamp',\n",
       " 'B4R4_Rzero_AC_MonteCarlo',\n",
       " 'B4R4_self_VANILLA']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./model',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "env = gym.make(\"cap-v0\") # initialize the environment\n",
    "\n",
    "done = False\n",
    "t = 0\n",
    "total_score = 0\n",
    "\n",
    "# reset the environment and select the policies for each of the team\n",
    "policy_red  = policy.zeros.PolicyGen(env.get_map, env.get_team_red)\n",
    "policy_blue = policy.policy_RL.PolicyGen(env.get_map, env.get_team_blue)\n",
    "observation = env.reset(map_size=20,\n",
    "                        policy_blue=policy_blue,\n",
    "                        policy_red=policy_red)\n",
    "\n",
    "pre_score = 0;\n",
    "while True:\n",
    "    t=0\n",
    "    while not done:\n",
    "        #you are free to select a random action\n",
    "        # or generate an action using the policy\n",
    "        # or select an action manually\n",
    "        # and the apply the selected action to blue team\n",
    "        # or use the policy selected and provided in env.reset \n",
    "        #action = env.action_space.sample()  # choose random action\n",
    "        #action = [0, 0, 0, 0]\n",
    "        action = policy_blue.gen_action(env.get_team_blue, env._env)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        #observation, reward, done, info = env.step()  # feedback from environment\n",
    "        #print(reward-pre_score, ' ',done)\n",
    "        #pre_score = reward;\n",
    "        \n",
    "        # render and sleep are not needed for score analysis\n",
    "        t += 1\n",
    "        env.render(mode=\"fast\")\n",
    "        if t == 150:\n",
    "            break\n",
    "\n",
    "    env.reset()\n",
    "    done = False\n",
    "    print(\"Time: %.2f s, score: %.2f\" %\n",
    "        ((time.time() - start_time),reward))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
