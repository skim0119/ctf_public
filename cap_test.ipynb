{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture the Flag (RL Policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import gym_cap\n",
    "import numpy as np\n",
    "\n",
    "# the modules that you can use to generate the policy.\n",
    "import policy.patrol \n",
    "import policy.random\n",
    "import policy.simple # custon written policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: Environment '<class 'gym_cap.envs.cap_env.CapEnvGenerate'>' has deprecated methods. Compatibility code invoked.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "env = gym.make(\"cap-v0\") # initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "t = 0\n",
    "total_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment and select the policies for each of the team\n",
    "policy_blue = policy.random.PolicyGen(env.get_map, env.get_team_blue)\n",
    "policy_red=policy.simple.PolicyGen(env.get_map, env.get_team_red)\n",
    "\n",
    "observation = env.reset(map_size=20,\n",
    "                        render_mode=\"env\",\n",
    "                        policy_blue=policy_blue,\n",
    "                        policy_red=policy_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-31da2ea8a12d>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-31da2ea8a12d>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    exit()\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    while not done:\n",
    "\n",
    "        #you are free to select a random action\n",
    "        # or generate an action using the policy\n",
    "        # or select an action manually\n",
    "        # and the apply the selected action to blue team\n",
    "        # or use the policy selected and provided in env.reset \n",
    "        #action = env.action_space.sample()  # choose random action\n",
    "        #action = policy_blue.gen_action(env.team1,observation,map_only=env.team_home)\n",
    "        #action = [0, 0, 0, 0]\n",
    "        #observation, reward, done, info = env.step(action)\n",
    "\n",
    "        observation, reward, done, info = env.step()  # feedback from environment\n",
    "\n",
    "        # render and sleep are not needed for score analysis\n",
    "        env.render(mode=\"slow\")\n",
    "        time.sleep(.05)\n",
    "\n",
    "        t += 1\n",
    "        if t == 100000:\n",
    "            break\n",
    "\n",
    "    total_score += reward\n",
    "    env.reset() \n",
    "    done = False\n",
    "    print(\"Total time: %0.02s s, score: %0.02s\" % ((time.time() - start_time),total_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
